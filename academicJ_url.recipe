from calibre.ptempfile import PersistentTemporaryFile
from calibre.web.feeds.news import BasicNewsRecipe
from calibre.ebooks.BeautifulSoup import BeautifulSoup
import re
import urllib

class BioinformaticsRecipe(BasicNewsRecipe):
  
	title = u'academic urls'
	__author__ = 'Robert M Flight'
	language = 'en'
	articles_are_obfuscated = True
	
	bmcJ = [re.compile('biomedcentral'), re.compile('http://www.biology-direct.com/'), re.compile('http://www.biodatamining.org/'), re.compile('http://journal.chemistrycentral.com/')]
	oxfordJ = [re.compile('oxfordjournals')]
	
	#remove_tags_before = dict(attrs={'class':'rounded custom white article full-text'})
	#remove_tags_after = dict(attrs={'id':'article-body'})
	
	temp_files = []
	
	def parse_index(self):
		feeds = []
		for title, url in [('Journal Articles', 'https://dl.dropbox.com/s/xflux6a6sq9szxi/testSimpleBioFeeds.txt')]:
			articles = self.bioinfo_parse_articles(url)
			if articles:
				feeds.append((title, articles))
			print feeds
		return feeds
		
	def bioinfo_parse_articles(self,url):
		urlFile = urllib.urlopen(url)
		useURL = urlFile.readlines()
		current_articles = []
	
		incTitle = 1
	
		for urlI in useURL:
			current_articles.append({'title': str(incTitle), 'url': urlI.strip(), 'description':'', 'date':''})
			incTitle = incTitle + 1
		return current_articles
		
	def oxford_images_tables(self, url, soup):
		url_split_char = '/'
		url_splitup = url.split(url_split_char)
		url_splitup.pop(-1)
		base_url = url_split_char.join(url_splitup)
		
		allImg = soup.findAll('img')
		
		for imgTag in allImg:
			tmpSrc = imgTag['src']
			tmpSrc = url_split_char.join([base_url, tmpSrc])
			if re.search('.small.gif', tmpSrc):
				tmpSrc = re.sub('.small.gif', '.large.jpg', tmpSrc)
				imgTag['width'] = 600
				
			imgTag['src'] = tmpSrc
			
		all_tables = soup.findAll('div', 'table-inline')
		
		for i_table in all_tables:
			a_link = i_table.find('a', 'in-nw')
			
			table_url = url_split_char.join([base_url, a_link['href']])
			table_soup = self.index_to_soup(table_url)
			
			table_div = table_soup.find('div', 'table-expansion ')
			
			i_table.replaceWith(table_div)
		
	# modifies the image paths and gets tables for bmc journals	
	def bmc_images_tables(self, url, soup):
		url_split_char = '/'
		url_splitup = url.split(url_split_char)
		
		# how many parts of the url to pop off to get to the base url
		# depends on whether it is a biomedcentral article, or another
		# bmc associated article. This works for BMC Bioinformatics and 
		# biodata mining at the very least
		if re.search('biomedcentral', url):
			nPop = 3
		else:
			nPop = 4
		
		for x in xrange(nPop):
			url_splitup.pop(-1) # removes the last three parts of the url
		
		image_baseURL = url_split_char.join(url_splitup)
		
		
		# work with the images
		allImages = soup.findAll('img')
		for imgLoc in allImages:
			imgSrc = imgLoc['src']
			tmpSrc = url_split_char.join([image_baseURL, imgSrc])
			imgLoc['src'] = tmpSrc
		
		
		allFigures = soup.findAll('div', 'fig')
		
		for figDiv in allFigures:
			imgTag = figDiv('img')[0]
			tmpSrc = imgTag['src']
			#tmpSrc = url_split_char.join([base_url, tmpSrc])
			if re.search('.gif', tmpSrc):
				tmpSrc = re.sub('.gif', '.jpg', tmpSrc)
				imgTag['width'] = 600
				
			imgTag['src'] = tmpSrc		


		# now with the tables
		all_tables = soup.findAll('div', 'table')
		
		for i_table in all_tables:
			#print i_table
			table_link = i_table('a')[0]['href']
			#print table_link
			#table_url = table_link[0
			#print table_url
			
			table_soup = self.index_to_soup(table_link)
			
			table_div = table_soup.find('table')
			
			i_table('a')[0].replaceWith(table_div)		
	
	# process each article, doing the tables and images for each one.
	def get_obfuscated_article(self, url):
		# this is the actual html of the page we are going to modify
		working_soup = self.index_to_soup(url)
		
		if any(r.search(url) for r in self.bmcJ):
			self.bmc_images_tables(url, working_soup)
		elif any(r.search(url) for r in self.oxfordJ):
			self.oxford_images_tables(url, working_soup)
		
		self.temp_files.append(PersistentTemporaryFile('_bioinf.html'))
		self.temp_files[-1].write(working_soup.prettify())
		self.temp_files[-1].close()
		return self.temp_files[-1].name 
