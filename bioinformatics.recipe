from calibre.web.feeds.news import BasicNewsRecipe
from calibre.ebooks.BeautifulSoup import BeautifulSoup
import re
import inspect

class BioinformaticsRecipe(BasicNewsRecipe):
  
    title = u'Bioinformatics Journal'
    language = 'en'
    oldest_article = 365
    feeds = [('Bioinformatics', 'https://dl.dropbox.com/s/m16gxh35ekf4qkk/bioinformatics_recent_test.rss')]
    #recursions = 1 # see if this gets us the table pages
    articles_are_obfuscated = True
    
    def print_version(self, url):
        url_rep = url.replace('/cgi', '')
        url_rep = url_rep.replace('/short', '')
        url_rep = url_rep.replace('?rss=1', '')
        dot_sep = '.'
        full_url = dot_sep.join([url_rep, 'full'])
        return full_url
        
#    def preprocess_raw_html(self, raw_html, url):
#        subbed_html = re.sub('.small.gif', '.large.jpg', raw_html)
#        return subbed_html
        
    # this switches to the large jpgs, and then sets a width limit on them
#    def preprocess_html(self, soup):
#        allImg = soup.findAll('img')
        #print allImg
#        for imgTag in allImg:
#            tmpSrc = imgTag['src']
#            if re.search('.small.gif', tmpSrc):
#                imgTag['src'] = re.sub('.small.gif', '.large.jpg', tmpSrc)
#                imgTag['width'] = 600
            
            
        #print allImg # check that things got changed
        #print soup.prettify()
        return soup
    
    def get_obfuscated_article(self, url):
        #print url
        # this is the actual html of the page we are going to modify
        working_soup = self.index_to_soup(url, False)
        
        url_split_char = '/'
        url_splitup = url.split(url_split_char)
        url_splitup.pop(-1)
        base_url = url_split_char.join(url_splitup)
        # this then needs to be processed, every img tag having the full url added
        # and then looking for tables and processing them
        # finally writing out the html to use
        allImg = working_soup.findAll('img')
        #print allImg
        for imgTag in allImg:
            tmpSrc = imgTag['src']
            tmpSrc = url_split_char.join([base_url, tmpSrc])
            if re.search('.small.gif', tmpSrc):
                tmpSrc = re.sub('.small.gif', '.large.jpg', tmpSrc)
                imgTag['width'] = 600
                
            imgTag['src'] = tmpSrc
                
        filePath = 'tmpfile.html'
        outFile = open(filePath, 'w')
        outFile.write(working_soup.prettify())
        return filePath
        
