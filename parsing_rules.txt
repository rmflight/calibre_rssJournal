Ways to parse various journals

**Oxford Journals**

Bioinformatics 

Tables - The full link is in a div denoted by: <div 'table-inline'>, with a link <a 'in-nw'>
	After fetching the page, the full table is then in a <div, 'table-expansion '>
	
Images - Take the base url of the paper, find all the <img src>, splice the url together, then replace "small.gif" with "large.jpg"

articles for testing:
http://bioinformatics.oxfordjournals.org/content/29/10/1268.full
http://bioinformatics.oxfordjournals.org/content/29/10/1275.full

Nucleic Acids Research

Tables - The full link is in a div denoted by: <div 'table-inline'>, with a link <a 'in-nw'>
	After fetching the page, the full table is then in a <div, 'table-expansion '>

Images - Take the base url of the paper, find all the <img src>, splice the url together, then replace "small.gif" with "large.jpg"


articles for testing:
http://nar.oxfordjournals.org/content/41/9/4743.full

**BMC Journals**

BMC Bioinformatics

Tables - The full link is in a <div class='table'>, with a link <a href='table-link'>
	After fetching the page, the full table is then in the <table> tag.
	
Images

find the <div class='fig'>, and take the <img src> link, and simply replace the .gif with .jpg, adding in the width tag

articles for testing:
http://www.biomedcentral.com/1471-2105/14/153
http://www.biomedcentral.com/1471-2164/14/298

BioDataMining
Same as BMC Bioinformatics, but images need to pop off 4

http://www.biodatamining.org/content/5/1/20

PLOS

Images
<div class="figure"><div class="img"><img src="">, replace I with M or L??

Tables are actually embedded as png images.

Other journals to do:

Science
Nature (hopefully all Nature articles work the same)
PNAS
PeerJ
Source Code for Biology and Medicine
Molecular Systems Biology
Genome Research (CSHL maybe??)

there are methods in calibre that might be useful

        def remove_beyond(tag, next):
            while tag is not None and getattr(tag, 'name', None) != 'body':
                after = getattr(tag, next)
                while after is not None:
                    ns = getattr(tag, next)
                    after.extract()
                    after = ns
                tag = tag.parent

        if self.remove_tags_after is not None:
            rt = [self.remove_tags_after] if isinstance(self.remove_tags_after, dict) else self.remove_tags_after
            for spec in rt:
                tag = soup.find(**spec)
                remove_beyond(tag, 'nextSibling')

        if self.remove_tags_before is not None:
            tag = soup.find(**self.remove_tags_before)
            remove_beyond(tag, 'previousSibling')

        for kwds in self.remove_tags:
            for tag in soup.findAll(**kwds):
                tag.extract()
        return self.preprocess_html_ext(soup)



PubmedCentral

Hmmm, there are issues with PMC, due to how different journals provide the raw data. However, there are links to download the epub. I could
probably create a recipe that simply downloads the epubs from PMC.
Tables
<div class='table-wrap ....'>, pop the last part of URL off, get the 

http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2386255/table/pone-0002265-t001/?report=thumb
http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2386255/bin/pone.0002265.t001.jpg
