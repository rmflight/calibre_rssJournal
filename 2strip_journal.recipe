from calibre.ptempfile import PersistentTemporaryFile
from calibre.web.feeds.news import BasicNewsRecipe
from calibre.ebooks.BeautifulSoup import BeautifulSoup
import re
import urllib

class BioinformaticsRecipe(BasicNewsRecipe):
  
	title = u'BMC Journals'
	__author__ = 'Robert M Flight'
	language = 'en'
	articles_are_obfuscated = True
	
	remove_tags_before = dict(attrs={'class':'rounded custom white article full-text'})
	remove_tags_after = dict(attrs={'id':'article-body'})
	
	temp_files = []
	
	def parse_index(self):
		feeds = []
		for title, url in [('Journal Articles', 'https://dl.dropbox.com/s/xflux6a6sq9szxi/testSimpleBioFeeds.txt')]:
			articles = self.bioinfo_parse_articles(url)
			if articles:
				feeds.append((title, articles))
			print feeds
		return feeds
		
	def bioinfo_parse_articles(self,url):
		urlFile = urllib.urlopen(url)
		useURL = urlFile.readlines()
		current_articles = []
	
		incTitle = 1
	
		for urlI in useURL:
			current_articles.append({'title': str(incTitle), 'url': urlI.strip(), 'description':'', 'date':''})
			incTitle = incTitle + 1
		return current_articles
		

   # feeds =[('Bioinformformatics', 'https://dl.dropbox.com/s/m16gxh35ekf4qkk/bioinformatics_recent_test.rss')]
 
	
	# because of "get_obfuscated_article", the relative links for images get messed.
	# this does two things: fixes the relative link, and for actual article "figures",
	# sets the link to the large figure, and inserts it into the html of the document
	def mod_image_paths(self, url, soup):
		# takes the full url and a BeautifulSoup instance, and modifies img paths
		url_split_char = '/'
		url_splitup = url.split(url_split_char)
		
		for x in xrange(3):
			url_splitup.pop(-1) # removes the last three parts of the url
		
		
		base_url = url_split_char.join(url_splitup)
		
		allImages = soup.findAll('img')
		for imgLoc in allImages:
			imgSrc = imgLoc['src']
			tmpSrc = url_split_char.join([base_url, imgSrc])
			imgLoc['src'] = tmpSrc
		
		
		allFigures = soup.findAll('div', 'fig')
		
		for figDiv in allFigures:
			imgTag = figDiv('img')[0]
			tmpSrc = imgTag['src']
			#tmpSrc = url_split_char.join([base_url, tmpSrc])
			if re.search('.gif', tmpSrc):
				tmpSrc = re.sub('.gif', '.jpg', tmpSrc)
				imgTag['width'] = 600
				
			imgTag['src'] = tmpSrc
			#print tmpSrc
			
		
	# takes the soup, and the url, and proceeds to find the tables in the doc, download
	# their html, and then insert the table into the original document
	def insert_tables(self, url, soup):
		# get the base url, same as we did for images
		url_split_char = '/'
		url_splitup = url.split(url_split_char)
		url_splitup.pop(-1)
		base_url = url_split_char.join(url_splitup)
		all_tables = soup.findAll('div', 'table')
		
		for i_table in all_tables:
			print i_table
			table_link = i_table('a')[0]['href']
			print table_link
			#table_url = table_link[0
			#print table_url
			
			table_soup = self.index_to_soup(table_link)
			
			table_div = table_soup.find('table')
			
			i_table('a')[0].replaceWith(table_div)
			
		#print all_tables # what is coming out

	 
	# takes the RSS CGI url and makes it a proper url pointing to the full version of the
	# article
 #   def print_version(self, url):
 #       url_rep = url.replace('/cgi', '')
 #       url_rep = url_rep.replace('/short', '')
 #       url_rep = url_rep.replace('?rss=1', '')
 #       dot_sep = '.'
 #       full_url = dot_sep.join([url_rep, 'full'])
 #       return full_url
	
	# process each article, doing the tables and images for each one.
	def get_obfuscated_article(self, url):
		# this is the actual html of the page we are going to modify
		working_soup = self.index_to_soup(url)
		
		self.mod_image_paths(url, working_soup)
		
		self.insert_tables(url, working_soup)
		
		self.temp_files.append(PersistentTemporaryFile('_bioinf.html'))
		#self.temp_files[-1].write(img_mod_soup.prettify())
		self.temp_files[-1].write(working_soup.prettify())
		self.temp_files[-1].close()
		return self.temp_files[-1].name 
